{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIPELINE FOR INTEGRATION OF ORDERS AND DETAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from order_details import load_order_details\n",
    "from order import load_order\n",
    "from exporting import export, export_data\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import os.path as Path\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from datetime import date, datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is running on 2022-07-26\n"
     ]
    }
   ],
   "source": [
    "#INPUTS\n",
    "INPUT_DATE = None\n",
    "# INPUT_DATE = '2021-01-01'\n",
    "\n",
    "if not INPUT_DATE is None:\n",
    "    INPUT_DATE =  datetime.strptime(INPUT_DATE, '%Y-%m-%d').date()\n",
    "\n",
    "ORDER_DETAILS_FILE = \"order_details.csv\"\n",
    "\n",
    "if INPUT_DATE is None:\n",
    "    date_base = date.today()\n",
    "else:\n",
    "    date_base = INPUT_DATE\n",
    "\n",
    "print(f\"Pipeline is running on {date_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASE PATHS\n",
    "PATH_BASE       = pathlib.Path(f\"{os.getcwd()}\").parent\n",
    "PATH_DATA       = f\"{PATH_BASE}/data\"\n",
    "PATH_DETAILS    = f\"{PATH_DATA}/{ORDER_DETAILS_FILE}\"\n",
    "PATH_POSTGRES   = f\"{PATH_DATA}/postgres\"\n",
    "PATH_CSV        = f\"{PATH_DATA}/csv\"\n",
    "PATH_RESULT     = f\"{PATH_DATA}/result\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from the PostgreSQL database...\n",
      "Connecting to the PostgreSQL database...\n",
      "PostgreSQL: selecting all tables ...\n",
      "PostgreSQL: extracting data from tables...\n",
      " 1/13 us_states\n",
      " 2/13 customers\n",
      " 3/13 orders\n",
      " 4/13 employees\n",
      " 5/13 shippers\n",
      " 6/13 categories\n",
      " 7/13 products\n",
      " 8/13 suppliers\n",
      " 9/13 region\n",
      " 10/13 territories\n",
      " 11/13 employee_territories\n",
      " 12/13 customer_demographics\n",
      " 13/13 customer_customer_demo\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "df_tables = load_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exctracting data from .csv file.\n",
      " ORDER_DETAILS: finished process\n"
     ]
    }
   ],
   "source": [
    "df_details = load_order_details(PATH_DETAILS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSFORM DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists_dir(path, create_dir=True):\n",
    "    if not Path.isdir(path):\n",
    "        if create_dir: \n",
    "            os.mkdir(path)\n",
    "            # print(f\"created {path}...\")\n",
    "        return False\n",
    "    else: \n",
    "        return True\n",
    "\n",
    "def exists_file(file_path):\n",
    "    return Path.exists(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable for exporting process\n",
    "export_process = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_today = str(date_base)\n",
    "file_datename = date_base.strftime('%s')\n",
    "\n",
    "#POSTGRESS\n",
    "exists_dir(PATH_POSTGRES)\n",
    "\n",
    "for table_name, df_table in df_tables:\n",
    "    PATH_TABLE = f\"{PATH_POSTGRES}/{table_name}\"\n",
    "    exists_dir(PATH_TABLE)\n",
    "    \n",
    "    PATH_TABLE_DATE = f\"{PATH_TABLE}/{date_today}\"\n",
    "    exists_dir(PATH_TABLE_DATE)\n",
    "\n",
    "    #name the exporting file\n",
    "    POSTGRES_FILE_NAME = f\"{PATH_TABLE_DATE}/{file_datename}.parquet\"\n",
    "    \n",
    "    #save on path \n",
    "    df_table.to_parquet(POSTGRES_FILE_NAME)\n",
    "    \n",
    "    #valid process for POSTGRES\n",
    "    created_postgres_file = exists_file(POSTGRES_FILE_NAME)\n",
    "    \n",
    "    if not created_postgres_file:\n",
    "        export_process = False\n",
    "        print(f\"{table_name}: Could not export file to {POSTGRES_FILE_NAME} path.\")\n",
    "\n",
    "#CSV\n",
    "exists_dir(PATH_CSV)\n",
    "\n",
    "for table_name, df_detail in df_details:\n",
    "    PATH_CSV_DATE = f\"{PATH_CSV}/{date_today}\"\n",
    "    exists_dir(PATH_CSV_DATE)\n",
    "\n",
    "    CSV_FILE_NAME = f\"{PATH_CSV_DATE}/{file_datename}.parquet\"\n",
    "            \n",
    "    #save on path \n",
    "    df_detail.to_parquet(CSV_FILE_NAME)\n",
    "\n",
    "    #valid process for CSV\n",
    "    created_csv_file =  exists_file(CSV_FILE_NAME)\n",
    "\n",
    "    if not created_csv_file:\n",
    "        export_process = False\n",
    "        print(f\"details: Could not export file to {CSV_FILE_NAME} path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      " Importing rows 0 to 51 for table us_states...\n",
      "  Data imported successfull for table us_states.\n",
      " Importing rows 51 to 100 for table employee_territories...\n",
      "  Data imported successfull for table employee_territories.\n",
      " No rows to be imported for table customer_customer_demo...\n",
      "  Table imported successfull on customer_customer_demo.\n",
      " Importing rows 100 to 106 for table shippers...\n",
      "  Data imported successfull for table shippers.\n",
      " Importing rows 106 to 183 for table products...\n",
      "  Data imported successfull for table products.\n",
      " No rows to be imported for table customer_demographics...\n",
      "  Table imported successfull on customer_demographics.\n",
      " Importing rows 183 to 274 for table customers...\n",
      "  Data imported successfull for table customers.\n",
      " Importing rows 274 to 283 for table employees...\n",
      "  Data imported successfull for table employees.\n",
      " Importing rows 283 to 336 for table territories...\n",
      "  Data imported successfull for table territories.\n",
      " Importing rows 336 to 340 for table region...\n",
      "  Data imported successfull for table region.\n",
      " Importing rows 340 to 369 for table suppliers...\n",
      "  Data imported successfull for table suppliers.\n",
      " Importing rows 369 to 1199 for table orders...\n",
      "  Data imported successfull for table orders.\n",
      " Importing rows 1199 to 1207 for table categories...\n",
      "  Data imported successfull for table categories.\n",
      " Importing rows 1207 to 3362 for table orders_details...\n",
      "  Data imported successfull for table orders_details.\n"
     ]
    }
   ],
   "source": [
    "if len(df_tables) > 0 and len(df_details) > 0:\n",
    "    #exists CSV path and FILE of the date\n",
    "    if not exists_dir(PATH_CSV_DATE, False):\n",
    "        continue_process = False\n",
    "        print(f\"Path of {PATH_CSV_DATE} have not been created, it means that process of exctracting have not been completed successfully.\")\n",
    "        \n",
    "    if not exists_file(CSV_FILE_NAME):\n",
    "        continue_process = False\n",
    "        print(f\"File on path {CSV_FILE_NAME} does not exists, it means that process of exctracting have not been completed successfully.\")\n",
    "\n",
    "    if export_process:\n",
    "        export(date_base)\n",
    "\n",
    "else:\n",
    "    print(\"Exporting process of orders and orders details have not been completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting local data to the PostgreSQL database...\n",
      " Connecting to the PostgreSQL database...\n",
      " 2155 results of the query...\n",
      " Database connection closed.\n",
      "Result exported on /home/leonardo/Documents/GitHub/Data_Engineering-Techindicium/data/result-2022-07-26.csv\n"
     ]
    }
   ],
   "source": [
    "df = export_data()\n",
    "\n",
    "FILE_RESULT = f\"{PATH_RESULT}-{date_today}.csv\"\n",
    "df.to_csv(FILE_RESULT, index=False)\n",
    "\n",
    "if exists_file(FILE_RESULT):\n",
    "    print(f\"Result exported on {FILE_RESULT}\")\n",
    "else:\n",
    "    print(f\"It was not possible to generate the file on {FILE_RESULT}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
